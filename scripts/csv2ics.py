# csv2ics.py

import csv
import os
import re
import argparse
import sys
import traceback
import json
from collections import defaultdict
from datetime import datetime
from zoneinfo import ZoneInfo
from ics import Calendar, Event
from ics.grammar.parse import ContentLine
from utils import validate_csv_path, ensure_output_dir, get_first_folder_from_path

GITHUB_USERNAME = None
REPO_NAME = None
DEFAULT_TIMEZONE = "America/Chicago"
CALENDAR_FOOTER = "Generated by Mark Hogan's Calendar Publisher"
MAX_UPLOAD_SIZE_MB = 5

def load_settings():
    global GITHUB_USERNAME, REPO_NAME, DEFAULT_TIMEZONE, CALENDAR_FOOTER, MAX_UPLOAD_SIZE_MB

    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            branding = json.load(f)

        GITHUB_USERNAME = branding.get("github_username", GITHUB_USERNAME)
        REPO_NAME = branding.get("repo_name", REPO_NAME)
        DEFAULT_TIMEZONE = branding.get("default_timezone", DEFAULT_TIMEZONE)
        CALENDAR_FOOTER = branding.get("calendar_footer", CALENDAR_FOOTER)
        MAX_UPLOAD_SIZE_MB = branding.get("max_upload_size_mb", MAX_UPLOAD_SIZE_MB)

    except FileNotFoundError:
        print(f"⚠️ settings.json not found at {config_path}. Using default values.")
    except json.JSONDecodeError as e:
        print(f"⚠️ Error parsing settings.json: {e}. Using default values.")
  
def find_column(columns, patterns):
    for pattern in patterns:
        regex = re.compile(pattern, re.IGNORECASE)
        for col in columns:
            if regex.match(col.strip()):
                return col
    return None

def apply_timezone1(dt_local, timezone_str):
    """
    Converts naive datetime to aware datetime in the given timezone.
    Assumes input is in local time.
    """
    return dt_local  # fallback to naive
    try:
        tz = ZoneInfo(timezone_str)
        # Step 1: Assume dt_local is in local time
        #dt_local = dt_local.replace(tzinfo=ZoneInfo("UTC"))  # or your assumed source zone
        dt_local = dt_local.replace(tz)  # or your assumed source zone
        # Step 2: Convert to target zone
        #return dt_local.astimezone(tz)
        return dt_local.astimezone(tzinfo=ZoneInfo("UTC"))
    except Exception as tz_err:
        print(f"⚠️ Timezone error: {tz_err}")
        return dt_local  # fallback to naive

def apply_timezone(dt_local, timezone_str, input_format="%m/%d/%Y %H:%M"):
    """
    Interprets a naive datetime or datetime string as being in the given local timezone,
    then converts it to GMT.
    """
    try:
        if dt_local is None:
            raise ValueError("Input datetime is None")

        local_tz = ZoneInfo(timezone_str)
        gmt_tz = ZoneInfo("UTC")

        # Parse string input
        if isinstance(dt_local, str):
            dt_local = datetime.strptime(dt_local.strip(), input_format)

        # Attach local timezone (assume input is local time)
        if dt_local.tzinfo is None:
            dt_local = dt_local.replace(tzinfo=local_tz)

        # Convert to GMT
        return dt_local.astimezone(gmt_tz)

    except Exception as tz_err:
        print(f"⚠️ Timezone error: {tz_err}")
        return dt_local  # fallback

def is_valid_iso_duration(ttl):
    return re.match(r"^P(T?\d+[HMS])?$", ttl) is not None

def add_ttl(cal, branding):
    ttl = branding.get("ttl", "P1D")
    if not is_valid_iso_duration(ttl):
        ttl = "P1D"  # fallback
    cal.extra.append(ContentLine(name="REFRESH-INTERVAL", params={"VALUE": ["DURATION"]}, value=ttl))
    #cal.extra.append(ContentLine(name="REFRESH-INTERVAL;VALUE=DURATION", value=ttl))
    cal.extra.append(ContentLine(name="X-PUBLISHED-TTL", value=ttl))
    line = ContentLine(name="REFRESH-INTERVAL", params={"VALUE": ["DURATION"]}, value=ttl)

def clean_datetime_string(dt_str):
    """
    Cleans and parses a wide variety of date/time strings into a datetime object.
    
    Args:
        dt_str (str): Raw date/time string.
    
    Returns:
        datetime or None: Parsed datetime object or None if invalid.
    """
    if not isinstance(dt_str, str):
        return None

    # Step 1: Normalize delimiters and casing
    dt_str = dt_str.strip()
    dt_str = re.sub(r"[.\-]", "/", dt_str)  # Convert . and - to /
    dt_str = re.sub(r"T", " ", dt_str)      # ISO T separator
    dt_str = re.sub(r"\s+", " ", dt_str)    # Collapse multiple spaces
    dt_str = dt_str.upper()                 # Normalize AM/PM casing

    # Step 2: Remove seconds if present (optional)
    dt_str = re.sub(r":(\d{2}):\d{2}", r":\1", dt_str)

    # Step 3: Try known formats
    known_formats = [
        "%m/%d/%Y %I:%M %p",     # 12/12/2025 3:45 PM
        "%m/%d/%Y %H:%M",        # 12/12/2025 15:45
        "%Y/%m/%d %H:%M",        # 2025/12/12 15:45
        "%Y/%m/%d %I:%M %p",     # 2025/12/12 3:45 PM
        "%Y/%m/%d",              # 2025/12/12
        "%m/%d/%Y",              # 12/12/2025
        "%B %d, %Y %I:%M %p",    # December 12, 2025 3:45 PM
        "%b %d, %Y %I:%M %p",    # Dec 12, 2025 3:45 PM
        "%Y-%m-%d %H:%M",        # ISO-like
        "%Y-%m-%d %I:%M %p",     # ISO-like with AM/PM
        "%Y-%m-%d",              # ISO date only
    ]

    for fmt in known_formats:
        try:
            return datetime.strptime(dt_str, fmt)
        except ValueError:
            continue

    return None  # No match

def parse_datetime(row, columns):
    start_dt_col = find_column(columns, ["^Start Date[- ]?Time$", "^Start.*Date.*Time$"])
    end_dt_col = find_column(columns, ["^End Date[- ]?Time$", "^End.*Date.*Time$"])

    if start_dt_col and end_dt_col:
        start = row[start_dt_col]
        end = row[end_dt_col]
        print(f"✅ Using combined datetime columns: {start_dt_col}, {end_dt_col}")
    else:
        cols_found = True
        missing = []
        date_col = find_column(columns, ["^Date$"])
        start_date_col = find_column(columns, ["^Start Date$", "^Date$"])
        start_time_col = find_column(columns, ["^Start Time$", "^Start.*Time$", "^Start$", "^start$"])
        end_date_col = find_column(columns, ["^End Date$", "^Date$"])
        end_time_col = find_column(columns, ["^End Time$", "^End.*Time$", "^End$", "^end$"])

        # Define required column pairs
        required_pairs = [
            ("date_col", date_col, "start_date_col", start_date_col),
            ("date_col", date_col, "start_time_col", start_time_col),
            ("date_col", date_col, "end_date_col", end_date_col),
            ("date_col", date_col, "end_time_col", end_time_col),
        ]

        for name1, col1, name2, col2 in required_pairs:
            if not col1 and not col2:
                cols_found = False
                if not col1:
                    missing.append(f"⚠️ {name1} is missing or empty.")
                if not col2:
                    missing.append(f"⚠️ {name2} is missing or empty.")

        if not cols_found:
            for msg in missing:
                print(msg)
            print("❌ Error Finding matching columns")
            raise ValueError("❌ Error Finding matching columns.")

        start_date = row.get(start_date_col) or row.get(date_col)
        start_time = row.get(start_time_col, "00:00")
        end_date = row.get(end_date_col) or row.get(date_col)
        end_time = row.get(end_time_col, "01:00")

        print(f"⚠️ Fallback datetime: {start_date} {start_time} → {end_date} {end_time}")
        
        start = f"{start_date} {start_time}"
        end = f"{end_date} {end_time}"

        start = clean_datetime_string(start)
        end = clean_datetime_string(end)

    #return start.strip(), end.strip()
    return start, end

def read_events(csv_file, team_name):
    events_by_team = defaultdict(list)
    samples = []
    with open(csv_file, newline='', encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        columns = reader.fieldnames

        team_col = find_column(columns, ["^Team$"])
        title_col = find_column(columns, ["^Event Title$", "^Title$"])
        desc_col = find_column(columns, ["^Description$"])
        location_col = find_column(columns, ["^Location$"])

        for i, row in enumerate(reader):
            team = row.get(team_col, team_name)
            start, end = parse_datetime(row, columns)

            if i < 5:
                samples.append((start, end))

            title = row.get(title_col) or row.get(desc_col) or "Untitled Event"
            description = row.get(desc_col) or row.get(title_col) or ""

            event = {
                "title": title,
                "start": start,
                "end": end,
                "location": row.get(location_col, ""),
                "description": description
            }
            events_by_team[team].append(event)
    return events_by_team, samples

def create_ics(team, events, output_dir, timezone=None, branding=None):
    cal = Calendar()

    # Branding defaults
    branding = branding or {}
    cal_name = branding.get("name", team)
    cal_desc = branding.get("description", f"Calendar for {team}")
    cal_color = branding.get("color")  # Optional, not standard in ICS
    cal_footer = branding.get("footer", "")

    # Calendar metadata
    cal.extra.append(ContentLine(name="X-WR-CALNAME", value=cal_name))
    cal.extra.append(ContentLine(name="NAME", value=cal_name))
    cal.extra.append(ContentLine(name="X-WR-CALDESC", value=cal_desc))
    if cal_color:
        cal.extra.append(ContentLine(name="X-APPLE-CALENDAR-COLOR", value=cal_color))  # Apple-specific
    add_ttl(cal, branding)

    for e in events:
        try:
            event = Event()
            event.name = e["title"]
            dt_start = e["start"]
            dt_end = e["end"]
            
            # Apply timezone if provided
            if timezone:
                try:
                    dt_save = dt_start
                    dt_start = apply_timezone(dt_start, timezone)
                    print(f"⚠️ apply_timezone '{dt_save}': {timezone} = {dt_start}")
                    dt_end = apply_timezone(dt_end, timezone)
                except Exception as tz_err:
                    print(f"⚠️ Timezone error for '{team}': {tz_err}")

            if dt_start:
                event.begin = dt_start
            if dt_end:
                if dt_end < dt_start:
                    dt_end = dt_end.replace(hour=23, minute=59, second=59, microsecond=0)
                event.end = dt_end
            event.location = e["location"]
            event.description = e["description"]
            cal.events.add(event)
        except ValueError as ve:
            print(f"❌ Error parsing event '{e['title']}': {ve}")
            print(f"❌     event dt_start: : {dt_start}")
            print(f"❌     event dt_end: : {dt_end}")
            raise

    # Optional footer event
    if cal_footer:
        footer_event = Event()
        footer_event.name = "Calendar Footer"
        footer_event.description = cal_footer
        footer_event.begin = dt_end  # Place it after last event
        footer_event.duration = {"minutes": 1}
        cal.events.add(footer_event)

    filename = f"{team.replace(' ', '_')}.ics"
    filepath = os.path.join(output_dir, filename)

    # Add blank lines after header and between events
    lines = cal.serialize().splitlines()
    output_lines = []
    for line in lines:
        output_lines.append(line)
        if line.strip() == "BEGIN:VCALENDAR":
            output_lines.append("")
        elif line.strip() == "END:VEVENT":
            output_lines.append("")

    with open(filepath, "w", encoding="utf-8") as f:
        f.write("\n".join(output_lines) + "\n")

    return filename

def generate_download_page(file_list, output_dir, github_username, repo_name, folder=None):
    base_url = f"https://{github_username}.github.io/{repo_name}"
    page_path = os.path.join(output_dir, "download_links.md")
    with open(page_path, "w", encoding="utf-8") as f:  # ✅ Add encoding
        f.write("# 🗓️ Team Calendar Downloads\n\n")
        for filename in file_list:
            team_name = filename.replace("_", " ")
            path = f"{folder}/{filename}" if folder else filename
            download_url = f"{base_url}/{path}"
            webcal_url = f"webcal://{base_url}/{path}"
            f.write(f"- **{team_name}**: [Download]({download_url}) | [Subscribe]({webcal_url})\n")

def generate_index_html(file_list, output_dir, github_username, repo_name, folder=None):
    base_url = f"{github_username}.github.io/{repo_name}"
    page_path = os.path.join(output_dir, "index.html")

    with open(page_path, "w", encoding="utf-8") as f:
        f.write("<!DOCTYPE html>\n")
        f.write("<html lang='en'>\n")
        f.write("<head>\n")
        f.write("  <meta charset='UTF-8'>\n")
        f.write("  <meta name='viewport' content='width=device-width, initial-scale=1.0'>\n")
        f.write("  <title>Team Calendar Links</title>\n")
        f.write("  <style>\n")
        f.write("    body { font-family: Arial, sans-serif; padding: 2em; }\n")
        f.write("    h1 { color: #2c3e50; }\n")
        f.write("    ul { list-style-type: none; padding: 0; }\n")
        f.write("    li { margin: 1em 0; }\n")
        f.write("    a { margin-right: 1em; text-decoration: none; color: #2980b9; }\n")
        f.write("  </style>\n")
        f.write("</head>\n")
        f.write("<body>\n")
        f.write("  <h1>🗓️ Team Calendar Links</h1>\n")
        f.write("  <ul>\n")

        for filename in file_list:
            team_name = filename.replace("_", " ").replace(".ics", "")
            path = f"{folder}/{filename}" if folder else filename
            download_url = f"https://{base_url}/{path}"
            webcal_url = f"webcal://{base_url}/{path}"

            f.write("    <li>\n")
            f.write(f"      <strong>{team_name}</strong><br>\n")
            f.write(f"      <a href='{download_url}' target='_blank'>Download</a>\n")
            f.write(f"      <a href='{webcal_url}' target='_blank'>Subscribe</a>\n")
            f.write("    </li>\n")

        f.write("  </ul>\n")
        f.write("</body>\n")
        f.write("</html>\n")

def generate_main_index(calendar_dir, output_dir, github_username, repo_name):
    #print(f"⚠️ '{calendar_dir}': {calendar_dir}")    
    #print(f"⚠️ '{output_dir}': {output_dir}")    
    #print(f"⚠️ '{github_username}': {github_username}")    
    #print(f"⚠️ '{repo_name}': {repo_name}")    
    base_url = f"https://{github_username}.github.io/{repo_name}"
    page_path = os.path.join(output_dir, "index.html")
    #print(f"⚠️ '{base_url}': {base_url}")    
    #print(f"⚠️ '{page_path}': {page_path}")    

    subfolders = [name for name in os.listdir(calendar_dir)
                  if os.path.isdir(os.path.join(calendar_dir, name))]

    with open(page_path, "w", encoding="utf-8") as f:
        f.write("<!DOCTYPE html>\n<html lang='en'>\n<head>\n")
        f.write("  <meta charset='UTF-8'>\n")
        f.write("  <title>Team Calendars</title>\n")
        f.write("  <style>body { font-family: sans-serif; padding: 2em; }</style>\n")
        f.write("</head>\n<body>\n")
        f.write("  <h1>📁 Team Calendars</h1>\n")
        f.write("  <ul>\n")

        for folder in sorted(subfolders):
            url = f"{base_url}/calendar/{folder}/"
            f.write(f"    <li><a href='{url}' target='_blank'>{folder.replace('_', ' ').title()}</a></li>\n")

        f.write("  </ul>\n</body>\n</html>\n")

def process_csv(input_or_config, output_dir=None):
    load_settings()
    # Determine mode: hosted (dict) or CLI (str)
    if isinstance(input_or_config, dict):
        # Hosted mode
        input_path = input_or_config.get("csv")
        output_dir = input_or_config.get("output", "calendars")
        timezone = input_or_config.get("timezone")
        branding = input_or_config.get("branding", {})
        team_name = input_or_config.get("name", "General")
    else:
        # CLI mode
        input_path = input_or_config
        output_dir = output_dir or "calendars"
        timezone = None
        branding = {}
        team_name = "General"

    validate_csv_path(input_path)
    ensure_output_dir(output_dir)

    if timezone:
        print(f"⚠️ Set Timezone to '{timezone}',")

    events_by_team, samples = read_events(input_path, team_name)

    generated_files = []
    for team, events in events_by_team.items():
        filename = create_ics(
            team,
            events,
            output_dir,
            timezone=timezone,
            branding=branding
        )
        generated_files.append(filename)

    generate_download_page(
        generated_files,
        output_dir,
        github_username=GITHUB_USERNAME,
        repo_name=REPO_NAME,
        folder=output_dir
    )
    generate_index_html(
        generated_files,
        output_dir,
        github_username=GITHUB_USERNAME,
        repo_name=REPO_NAME,
        folder=output_dir
    )
    generate_main_index(
        calendar_dir=get_first_folder_from_path(output_dir),
        output_dir="docs",
        github_username=GITHUB_USERNAME,
        repo_name=REPO_NAME
    )

    return {
        "output_dir": output_dir,
        "generated_files": generated_files
    }

def main():
    parser = argparse.ArgumentParser(
        description="📅 Generate ICS calendar files from a CSV with auto-detected or manual datetime format.",
        formatter_class=argparse.RawTextHelpFormatter
    )

    parser.add_argument(
        "--input", "-i",
        default="events.csv",
        help="Path to input CSV file (default: events.csv)"
    )
    parser.add_argument(
        "--output", "-o",
        default="calendars",
        help="Directory to save generated ICS files (default: calendars)"
    )
    parser.add_argument(
        "--datetime-format", "-f",
        help="Optional datetime format override (e.g. \"%m/%d/%Y %I:%M %p\")"
    )

    args = parser.parse_args()

    print(f"\n📁 Input CSV: {args.input}")
    print(f"📂 Output Directory: {args.output}")

    try:
        result = process_csv(
            input_path=args.input,
            output_dir=args.output
        )

        print(f"\n✅ Generated {len(result['generated_files'])} ICS file(s):")
        for fname in result["generated_files"]:
            print(f"   - {fname}")
        print(f"\n📄 Download page saved to: {os.path.join(result['output_dir'], 'download_links.md')}")

    except Exception as e:
        print(f"\n❌ Failed to generate calendars: [{type(e).__name__}] {e}")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
